{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 对齐代码2：histogram 输入使用“未标准化 raw + 非负截断（<=0置0）”，并用 baseline/bin 分箱 + z-score\n",
    "# 说明：本脚本只针对“对比模型分支（hist+StevieNet）”严格复现代码2的 my_binning 输入体系；\n",
    "#       不再对直方图输入做 StandardScaler（你原代码里的 scaler 逻辑已移除/绕开）。\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_FRACTION = 1  # 改成 0.1 即使用清洗后训练集的 10%\n",
    "\n",
    "# =========================================================\n",
    "# 0) 读取数据\n",
    "# =========================================================\n",
    "# parquet_path = \"/content/drive/MyDrive/CA-AA/Cleandata_Lable20_N157794_ML30_MU3000.parquet\"\n",
    "parquet_path = \"/content/drive/MyDrive/CA-AA/Cleandata5_Lable20_N83597_5000_ML30_MU3000.parquet\"\n",
    "data = pd.read_parquet(parquet_path)\n",
    "print(\"读取完成:\", data.shape)\n",
    "\n",
    "# =========================================================\n",
    "# 1) 字段约定\n",
    "#   第1列：label\n",
    "#   第2列：baseline\n",
    "#   第4列开始：时序特征\n",
    "# =========================================================\n",
    "label_col = data.columns[0]\n",
    "baseline_col = data.columns[1]\n",
    "feature_cols = data.columns[3:]  # 第4列开始为时序特征\n",
    "\n",
    "# =========================================================\n",
    "# 2) Step 1: 计算每个样本有效长度（非零个数）\n",
    "# =========================================================\n",
    "data = data.copy()\n",
    "data[\"valid_length\"] = (data[feature_cols] != 0).sum(axis=1)\n",
    "\n",
    "# =========================================================\n",
    "# 3) Step 2: 按标签剔除异常（你原来是 0.35~0.65 分位）\n",
    "# =========================================================\n",
    "def remove_outliers_by_label(df):\n",
    "    q_low = df[\"valid_length\"].quantile(0.35)\n",
    "    q_high = df[\"valid_length\"].quantile(0.65)\n",
    "    return df[(df[\"valid_length\"] >= q_low) & (df[\"valid_length\"] <= q_high)]\n",
    "\n",
    "cleaned_data = (\n",
    "    data.groupby(label_col, group_keys=False)\n",
    "        .apply(remove_outliers_by_label)\n",
    ")\n",
    "\n",
    "cleaned_data = cleaned_data.drop(columns=[\"valid_length\"])\n",
    "print(f\"清洗前样本数: {len(data)}\")\n",
    "print(f\"清洗后样本数: {len(cleaned_data)}\")\n",
    "\n",
    "data = cleaned_data\n",
    "del cleaned_data\n",
    "gc.collect()\n",
    "\n",
    "# =========================================================\n",
    "# 4) Step 3: 删除指定标签\n",
    "# =========================================================\n",
    "remove_labels = [8, 12, 14]  # 你原代码\n",
    "data = data[~data.iloc[:, 0].isin(remove_labels)].copy()\n",
    "print(\"删除标签后 shape:\", data.shape)\n",
    "\n",
    "# =========================================================\n",
    "# 5) 提取 label / baseline / raw 序列（注意：此 raw 将作为 histogram 输入，不做 StandardScaler）\n",
    "# =========================================================\n",
    "labels = data[label_col].values.astype(np.int64)          # (N,)\n",
    "baselines = data[baseline_col].values.astype(np.float32)  # (N,)\n",
    "raw = data[feature_cols].values.astype(np.float32)        # (N, L)\n",
    "\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "# =========================================================\n",
    "# 6) 拆分：train / val / test（baseline 同步拆分）\n",
    "# =========================================================\n",
    "raw_train, raw_tmp, y_train, y_tmp, b_train, b_tmp = train_test_split(\n",
    "    raw, labels, baselines,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "raw_val, raw_test, y_val, y_test, b_val, b_test = train_test_split(\n",
    "    raw_tmp, y_tmp, b_tmp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_tmp\n",
    ")\n",
    "\n",
    "del raw, raw_tmp, y_tmp, b_tmp\n",
    "gc.collect()\n",
    "\n",
    "print(f\"训练集样本数（拆分后）：{len(raw_train)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 7) 训练集清洗1：按非零长度去除每标签最小/最大 x%\n",
    "# =========================================================\n",
    "x = 0.0  # 你原代码保持 0.0\n",
    "keep_idx = []\n",
    "for lbl in np.unique(y_train):\n",
    "    idxs = np.where(y_train == lbl)[0]\n",
    "    nz = (raw_train[idxs] != 0).sum(axis=1)\n",
    "    order = idxs[np.argsort(nz)]\n",
    "    n = len(order)\n",
    "    low, high = int(n * x), int(n * (1 - x))\n",
    "    keep_idx.extend(order[low:high])\n",
    "\n",
    "keep_idx = np.sort(np.array(keep_idx))\n",
    "raw_train = raw_train[keep_idx]\n",
    "y_train   = y_train[keep_idx]\n",
    "b_train   = b_train[keep_idx]\n",
    "gc.collect()\n",
    "\n",
    "# =========================================================\n",
    "# 8) 训练集清洗2：按“最大下降幅度”去除每标签最小/最大 x%\n",
    "# =========================================================\n",
    "x = 0.0  # 同上\n",
    "def calc_max_drop_amp(arr):\n",
    "    v = arr[~np.isnan(arr) & (arr != 0)]\n",
    "    if v.size == 0:\n",
    "        return 0.0\n",
    "    m = np.argmax(v)\n",
    "    s = max(0, m - 10)\n",
    "    e = min(v.size, m + 11)\n",
    "    return abs(v[s:e].mean())\n",
    "\n",
    "amps = np.apply_along_axis(calc_max_drop_amp, 1, raw_train)\n",
    "\n",
    "keep2 = []\n",
    "for lbl in np.unique(y_train):\n",
    "    idxs = np.where(y_train == lbl)[0]\n",
    "    order = idxs[np.argsort(amps[idxs])]\n",
    "    n = len(order)\n",
    "    low, high = int(n * x), int(n * (1 - x))\n",
    "    keep2.extend(order[low:high])\n",
    "\n",
    "keep2 = np.sort(np.array(keep2))\n",
    "raw_train = raw_train[keep2]\n",
    "y_train   = y_train[keep2]\n",
    "b_train   = b_train[keep2]\n",
    "\n",
    "del amps, keep_idx, keep2\n",
    "gc.collect()\n",
    "\n",
    "print(f\"训练集样本数（清洗后）：{len(raw_train)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 8.1) 训练集下采样：用 TRAIN_FRACTION 控制训练集规模（如 0.1 表示 10%）\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "if 0.0 < TRAIN_FRACTION < 1.0:\n",
    "    rng = np.random.RandomState(42)\n",
    "    selected_idx = []\n",
    "\n",
    "    # 按标签分层下采样，尽量保持类别分布\n",
    "    for lbl in np.unique(y_train):\n",
    "        idxs = np.where(y_train == lbl)[0]\n",
    "        n_lbl = len(idxs)\n",
    "        n_keep_lbl = max(1, int(n_lbl * TRAIN_FRACTION))\n",
    "        chosen = rng.choice(idxs, size=n_keep_lbl, replace=False)\n",
    "        selected_idx.extend(chosen)\n",
    "\n",
    "    selected_idx = np.array(selected_idx)\n",
    "    raw_train = raw_train[selected_idx]\n",
    "    y_train   = y_train[selected_idx]\n",
    "    b_train   = b_train[selected_idx]\n",
    "\n",
    "    print(f\"训练集样本数（下采样后，比例={TRAIN_FRACTION:.2f}）：{len(raw_train)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 9) 关键改动：对比模型（hist）分支不做 StandardScaler\n",
    "#    直接把 raw_* 转 torch，后续 histogram 内部做 nan_to_num + 非负截断\n",
    "# =========================================================\n",
    "X_train = torch.tensor(raw_train, dtype=torch.float32)\n",
    "X_val   = torch.tensor(raw_val,   dtype=torch.float32)\n",
    "X_test  = torch.tensor(raw_test,  dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val   = torch.tensor(y_val,   dtype=torch.long)\n",
    "y_test  = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "baseline_train = torch.tensor(b_train, dtype=torch.float32)\n",
    "baseline_val   = torch.tensor(b_val,   dtype=torch.float32)\n",
    "baseline_test  = torch.tensor(b_test,  dtype=torch.float32)\n",
    "\n",
    "del raw_train, raw_val, raw_test, b_train, b_val, b_test\n",
    "gc.collect()\n",
    "\n",
    "# =========================================================\n",
    "# 10) 通道构造：保持你原来的逻辑（默认单通道）\n",
    "# =========================================================\n",
    "use_sliding_std = 0\n",
    "ws = 10\n",
    "\n",
    "def sliding_std(x: torch.Tensor, window_size: int) -> torch.Tensor:\n",
    "    patches = x.unfold(1, window_size, 1)              # (N, L-ws+1, ws)\n",
    "    stds = patches.std(dim=2, unbiased=False)          # (N, L-ws+1)\n",
    "    pad_l = (window_size - 1) // 2\n",
    "    pad_r = window_size - 1 - pad_l\n",
    "    return F.pad(stds, (pad_l, pad_r), value=0.0)      # (N, L)\n",
    "\n",
    "if use_sliding_std:\n",
    "    std_tr = sliding_std(X_train, ws)\n",
    "    std_v  = sliding_std(X_val,   ws)\n",
    "    std_te = sliding_std(X_test,  ws)\n",
    "\n",
    "    X_train = torch.stack([X_train, std_tr], dim=1)    # (N,2,L)\n",
    "    X_val   = torch.stack([X_val,   std_v],  dim=1)\n",
    "    X_test  = torch.stack([X_test,  std_te], dim=1)\n",
    "\n",
    "    del std_tr, std_v, std_te\n",
    "    gc.collect()\n",
    "else:\n",
    "    X_train = X_train.unsqueeze(1)  # (N,1,L)\n",
    "    X_val   = X_val.unsqueeze(1)\n",
    "    X_test  = X_test.unsqueeze(1)\n",
    "\n",
    "# baseline > 0 保护（避免 p_step=0）\n",
    "baseline_train = baseline_train.clamp_min(1e-8)\n",
    "baseline_val   = baseline_val.clamp_min(1e-8)\n",
    "baseline_test  = baseline_test.clamp_min(1e-8)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}, baseline_train: {baseline_train.shape}\")\n",
    "print(f\"X_val  : {X_val.shape},   y_val  : {y_val.shape},   baseline_val  : {baseline_val.shape}\")\n",
    "print(f\"X_test : {X_test.shape},  y_test : {y_test.shape},  baseline_test : {baseline_test.shape}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 11) baseline sanity check\n",
    "# =========================================================\n",
    "def _check_baseline(x, b, y, name=\"train\"):\n",
    "    assert isinstance(x, torch.Tensor) and isinstance(b, torch.Tensor) and isinstance(y, torch.Tensor)\n",
    "    assert x.dim() == 3, f\"{name}: X must be (N,C,L), got {x.shape}\"\n",
    "    assert y.dim() == 1, f\"{name}: y must be (N,), got {y.shape}\"\n",
    "    assert b.dim() == 1, f\"{name}: baseline must be (N,), got {b.shape}\"\n",
    "    assert x.size(0) == y.size(0) == b.size(0), f\"{name}: N mismatch: X={x.size(0)}, y={y.size(0)}, b={b.size(0)}\"\n",
    "    b = b.float().clamp_min(1e-8)\n",
    "    y = y.long()\n",
    "    return x, b, y\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 12) 直方图映射：对齐代码2.my_binning\n",
    "# =========================================================\n",
    "class MyBinningTorch(nn.Module):\n",
    "    def __init__(self, bin: int):\n",
    "        super().__init__()\n",
    "        self.bin = int(bin)\n",
    "\n",
    "    @staticmethod\n",
    "    def _standardize(P: torch.Tensor, eps: float = 1e-8):\n",
    "        mean = P.mean(dim=-1, keepdim=True)\n",
    "        std = P.std(dim=-1, keepdim=True)\n",
    "        out = (P - mean) / (std + eps)\n",
    "        out = torch.where(std > 0, out, torch.zeros_like(out))  # std==0 时置0\n",
    "        return out\n",
    "\n",
    "    def forward(self, sequence: torch.Tensor, baseline: torch.Tensor):\n",
    "        \"\"\"\n",
    "        sequence: (B, L) float\n",
    "        baseline: (B,)  float\n",
    "        return  : (B, bin) float\n",
    "        \"\"\"\n",
    "        if sequence.dim() != 2:\n",
    "            raise ValueError(f\"sequence must be (B,L), got {sequence.shape}\")\n",
    "        if baseline.dim() != 1:\n",
    "            raise ValueError(f\"baseline must be (B,), got {baseline.shape}\")\n",
    "\n",
    "        B, L = sequence.shape\n",
    "\n",
    "        # 对齐代码2：nan/inf -> 0\n",
    "        x = torch.nan_to_num(sequence, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # 对齐代码2：小于等于0的都替换为0（temp>0 else 0）\n",
    "        x = torch.clamp(x, min=0.0)\n",
    "\n",
    "        baseline = baseline.clamp_min(1e-8)\n",
    "        p_step = baseline / self.bin  # (B,)\n",
    "\n",
    "        s = torch.floor(x / p_step.unsqueeze(1)).long()  # (B,L)\n",
    "        s = s.clamp_(0, self.bin - 1)\n",
    "\n",
    "        P = torch.zeros(B, self.bin, device=x.device, dtype=torch.float32)\n",
    "        ones = torch.ones(B, L, device=x.device, dtype=torch.float32)\n",
    "        P.scatter_add_(dim=1, index=s, src=ones)\n",
    "\n",
    "        return self._standardize(P)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 13) StevieNet（ResNet1D）\n",
    "# =========================================================\n",
    "class Bottleneck1D(nn.Module):\n",
    "    extention = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * self.extention, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * self.extention)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out = self.relu(out + residual)\n",
    "        return out\n",
    "\n",
    "\n",
    "class StevieNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_class, input_channels=1):\n",
    "        super().__init__()\n",
    "        self.inplane = 64\n",
    "        self.conv1 = nn.Conv1d(input_channels, self.inplane, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.inplane)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.stage1 = self.make_layer(block, 64, layers[0], stride=1)\n",
    "        self.stage2 = self.make_layer(block, 128, layers[1], stride=2)\n",
    "        self.stage3 = self.make_layer(block, 256, layers[2], stride=2)\n",
    "        self.stage4 = self.make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512 * block.extention, num_class)\n",
    "\n",
    "    def make_layer(self, block, plane, block_num, stride=1):\n",
    "        block_list = []\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplane != plane * block.extention:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplane, plane * block.extention, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm1d(plane * block.extention),\n",
    "            )\n",
    "        block_list.append(block(self.inplane, plane, stride=stride, downsample=downsample))\n",
    "        self.inplane = plane * block.extention\n",
    "        for _ in range(1, block_num):\n",
    "            block_list.append(block(self.inplane, plane, stride=1))\n",
    "        return nn.Sequential(*block_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.stage1(out)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        return self.fc(out)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 14) 对比模型封装：hist + StevieNet（forward/predict 需要 baseline）\n",
    "# =========================================================\n",
    "class StevieNetHistBaseline(nn.Module):\n",
    "    def __init__(self, num_classes=20, bin=1024, threshold=0.9, input_use_channel0=True):\n",
    "        super().__init__()\n",
    "        self.hist = MyBinningTorch(bin=int(bin))\n",
    "        self.backbone = StevieNet(Bottleneck1D, layers=[3, 4, 6, 3], num_class=num_classes, input_channels=1)\n",
    "        self.threshold = float(threshold)\n",
    "        self.input_use_channel0 = bool(input_use_channel0)\n",
    "\n",
    "    def forward(self, x, baseline):\n",
    "        # x: (B, C, L)\n",
    "        if self.input_use_channel0:\n",
    "            seq = x[:, 0, :]          # (B,L)\n",
    "        else:\n",
    "            seq = x.mean(dim=1)       # (B,L)\n",
    "\n",
    "        hist_vec = self.hist(seq, baseline)      # (B,bin)\n",
    "        hist_vec = hist_vec.unsqueeze(1)         # (B,1,bin)\n",
    "        logits = self.backbone(hist_vec)         # (B,num_classes)\n",
    "        return logits\n",
    "\n",
    "    def predict(self, x, baseline):\n",
    "        logits = self.forward(x, baseline)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        conf, pred = torch.max(probs, dim=1)\n",
    "        pred = pred.clone()\n",
    "        pred[conf < self.threshold] = -1\n",
    "        return pred, conf\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 16) 训练准备\n",
    "# =========================================================\n",
    "X_train, baseline_train, y_train = _check_baseline(X_train, baseline_train, y_train, \"train\")\n",
    "X_val,   baseline_val,   y_val   = _check_baseline(X_val,   baseline_val,   y_val,   \"val\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_CLASSES = 20\n",
    "BIN = 256\n",
    "EPOCHS = 40\n",
    "BATCH = 64\n",
    "THRESH = 0\n",
    "\n",
    "model = StevieNetHistBaseline(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    bin=BIN,\n",
    "    threshold=THRESH,\n",
    "    input_use_channel0=True\n",
    ").to(device)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, baseline_train, y_train),\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(X_val, baseline_val, y_val),\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=EPOCHS,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    "    final_div_factor=1e4\n",
    ")\n",
    "\n",
    "# 固定不变：不再动态调整类别权重\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_accs, val_accs_max, val_accs_pred, coverages = [], [], [], []\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 17) Training Loop\n",
    "# =========================================================\n",
    "for epoch in range(EPOCHS):\n",
    "    # —— train ——\n",
    "    model.train()\n",
    "    correct = total = 0\n",
    "\n",
    "    for xb, bb, yb in train_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        bb = bb.to(device, non_blocking=True).float().clamp_min(1e-8)\n",
    "        yb = yb.to(device, non_blocking=True).long()\n",
    "\n",
    "        logits = model(xb, bb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    train_accs.append(100.0 * correct / max(total, 1))\n",
    "\n",
    "    # —— validate ——\n",
    "    model.eval()\n",
    "    cm_max = cm_pred = total_max = total_pred = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, bb, yb in val_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            bb = bb.to(device, non_blocking=True).float().clamp_min(1e-8)\n",
    "            yb = yb.to(device, non_blocking=True).long()\n",
    "\n",
    "            logits = model(xb, bb)\n",
    "\n",
    "            # Val Acc(max)\n",
    "            pm = logits.argmax(dim=1)\n",
    "            cm_max += (pm == yb).sum().item()\n",
    "            total_max += yb.size(0)\n",
    "\n",
    "            # Val Acc(pred) with rejection\n",
    "            pp, conf = model.predict(xb, bb)\n",
    "            mask = (pp != -1)\n",
    "            if mask.any():\n",
    "                cm_pred += (pp[mask] == yb[mask]).sum().item()\n",
    "                total_pred += mask.sum().item()\n",
    "\n",
    "    val_accs_max.append(100.0 * cm_max / max(total_max, 1))\n",
    "    val_accs_pred.append(100.0 * cm_pred / total_pred if total_pred > 0 else 0.0)\n",
    "    coverages.append(100.0 * (total_pred / max(total_max, 1)))\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"Train Acc: {train_accs[-1]:.2f}% | \"\n",
    "          f\"Val Acc(max): {val_accs_max[-1]:.2f}% | \"\n",
    "          f\"Val Acc(pred): {val_accs_pred[-1]:.2f}% | \"\n",
    "          f\"Coverage: {coverages[-1]:.1f}%\")\n",
    "\n",
    "# =========================================================\n",
    "# 18) 可视化\n",
    "# =========================================================\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accs, label=\"Train Acc\")\n",
    "plt.plot(val_accs_max, label=\"Val Acc (max)\")\n",
    "plt.plot(val_accs_pred, label=\"Val Acc (predict, with rejection)\")\n",
    "plt.plot(coverages, label=\"Coverage (%)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy / %\")\n",
    "plt.title(\"Training Curve: StevieNet + my_binning(raw+nonneg) + rejection\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.threshold = 0 # 修改为你想要测试的阈值\n",
    "'''\n",
    "# 以下为门槛值超参数搜索环节，可选\n",
    "# =========================================================# =========================================================# =========================================================# =========================================================\n",
    "\n",
    "\n",
    "\n",
    "# ================= Validation: threshold calibration + per-class gate stats + report (baseline-aware) =================\n",
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# ----------------- A) 配置：选择校准策略 -----------------\n",
    "CAL_POLICY      = \"target_coverage\"   # \"target_coverage\" 或 \"target_risk\"\n",
    "TARGET_VALUE    = 0.65                # coverage目标(0~1) 或 risk目标(0~1)\n",
    "CALIB_BATCHSIZE = 512\n",
    "PLOT_CALIB      = True\n",
    "SAVE_JSON_PATH  = \"./val_gate_stats.json\"\n",
    "\n",
    "\n",
    "# ----------------- B) 在验证集上标定阈值（风险-覆盖率） -----------------\n",
    "@torch.no_grad()\n",
    "def calibrate_threshold_on_val(model, X_val, baseline_val, y_val,\n",
    "                               device=\"cpu\", batch_size=512,\n",
    "                               policy=\"target_coverage\", target=0.90,\n",
    "                               plot=True):\n",
    "    \"\"\"\n",
    "    选择性分类标定 Softmax 阈值（baseline-aware）：\n",
    "      - 取每个样本最大置信度 conf 与是否预测正确 correct\n",
    "      - conf 降序 -> (coverage, acc_on_accepted, risk) 曲线\n",
    "      - policy=\"target_coverage\": 覆盖率>=target 的区间内选 risk 最小点\n",
    "        policy=\"target_risk\": risk<=target 的区间内选 coverage 最大点\n",
    "    返回：thr_star, cov_star, acc_star，并写回 model.threshold\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # ✅ DataLoader：多了 baseline_val\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(X_val, baseline_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    confs, corrects = [], []\n",
    "    for xb, bb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        bb = bb.to(device, non_blocking=True).float().clamp_min(1e-8)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        # ✅ 关键改动：模型前向需要 baseline\n",
    "        logits = model(xb, bb)\n",
    "        probs  = F.softmax(logits, dim=1)\n",
    "        conf, pred = probs.max(dim=1)\n",
    "\n",
    "        confs.append(conf.detach().cpu())\n",
    "        corrects.append((pred == yb).detach().cpu())\n",
    "\n",
    "    confs   = torch.cat(confs).numpy()\n",
    "    correct = torch.cat(corrects).numpy().astype(np.int32)\n",
    "    N = len(confs)\n",
    "    if N == 0:\n",
    "        raise RuntimeError(\"Validation set is empty, cannot calibrate threshold.\")\n",
    "\n",
    "    order = np.argsort(-confs)\n",
    "    conf_sorted    = confs[order]\n",
    "    correct_sorted = correct[order]\n",
    "\n",
    "    k = np.arange(1, N + 1)\n",
    "    coverage = k / N\n",
    "    acc_on_accepted = np.cumsum(correct_sorted) / k\n",
    "    risk = 1.0 - acc_on_accepted\n",
    "\n",
    "    if policy == \"target_coverage\":\n",
    "        idx0 = int(np.searchsorted(coverage, target, side=\"left\"))\n",
    "        idx0 = np.clip(idx0, 0, N - 1)\n",
    "        tail = np.arange(idx0, N)\n",
    "        idx_star = int(tail[np.argmin(risk[tail])])\n",
    "    elif policy == \"target_risk\":\n",
    "        ok = np.where(risk <= target)[0]\n",
    "        idx_star = int(ok[-1]) if ok.size > 0 else int(np.argmin(risk))\n",
    "    else:\n",
    "        raise ValueError(\"CAL_POLICY must be 'target_coverage' or 'target_risk'.\")\n",
    "\n",
    "    thr_star = float(conf_sorted[idx_star])\n",
    "    cov_star = float(coverage[idx_star])\n",
    "    acc_star = float(acc_on_accepted[idx_star])\n",
    "\n",
    "    model.threshold = thr_star\n",
    "\n",
    "    print(\"\\n[Calibration]\")\n",
    "    print(f\"  policy = {policy}, target = {target}\")\n",
    "    print(f\"  -> threshold = {thr_star:.4f}\")\n",
    "    print(f\"  -> coverage  = {cov_star*100:.2f}%\")\n",
    "    print(f\"  -> acc_on_accepted (1-risk) = {acc_star*100:.2f}%\")\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(12, 4.5))\n",
    "        ax1 = fig.add_subplot(1, 2, 1)\n",
    "        ax1.hist(confs[correct == 1], bins=40, alpha=0.6, label=\"Correct\", density=True)\n",
    "        ax1.hist(confs[correct == 0], bins=40, alpha=0.6, label=\"Incorrect\", density=True)\n",
    "        ax1.axvline(thr_star, ls=\"--\", c=\"k\", label=f\"Threshold {thr_star:.2f}\")\n",
    "        ax1.set_xlabel(\"Max softmax confidence\")\n",
    "        ax1.set_ylabel(\"Density\")\n",
    "        ax1.set_title(\"Validation confidence distribution\")\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2 = fig.add_subplot(1, 2, 2)\n",
    "        ax2.plot(coverage, acc_on_accepted, lw=2)\n",
    "        ax2.scatter([cov_star], [acc_star], s=50, edgecolors=\"k\",\n",
    "                    label=f\"Chosen: cov={cov_star*100:.1f}%, acc={acc_star*100:.2f}%\")\n",
    "        ax2.set_xlabel(\"Coverage (accepted proportion)\")\n",
    "        ax2.set_ylabel(\"Accuracy on accepted (Precision)\")\n",
    "        ax2.set_title(\"Accuracy–Coverage curve (validation)\")\n",
    "        ax2.set_xlim(0.2, 1)\n",
    "        ax2.set_ylim(0.0, 1.0)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return thr_star, cov_star, acc_star\n",
    "\n",
    "\n",
    "# ----------------- C) 先标定阈值 -----------------\n",
    "thr_star, cov_star, acc_star = calibrate_threshold_on_val(\n",
    "    model, X_val, baseline_val, y_val,\n",
    "    device=device,\n",
    "    batch_size=CALIB_BATCHSIZE,\n",
    "    policy=CAL_POLICY,\n",
    "    target=TARGET_VALUE,\n",
    "    plot=PLOT_CALIB\n",
    ")\n",
    "print(f\"[Model] model.threshold 已设置为 {model.threshold:.4f}\")\n",
    "\n",
    "\n",
    "# ----------------- D) 用选定阈值统计每类 gate 参数并缓存 -----------------\n",
    "@torch.no_grad()\n",
    "def compute_val_gate_stats(model, X_val, baseline_val, y_val, thr,\n",
    "                           device=\"cpu\", batch_size=512):\n",
    "    model.eval()\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(X_val, baseline_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    y_true_list, y_hat_list, p_max_list = [], [], []\n",
    "    for xb, bb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        bb = bb.to(device, non_blocking=True).float().clamp_min(1e-8)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(xb, bb)\n",
    "        probs  = F.softmax(logits, dim=1)\n",
    "        p_max, y_hat = probs.max(dim=1)\n",
    "\n",
    "        y_true_list.append(yb.detach().cpu())\n",
    "        y_hat_list.append(y_hat.detach().cpu())\n",
    "        p_max_list.append(p_max.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true_list).numpy()\n",
    "    y_hat  = torch.cat(y_hat_list).numpy()\n",
    "    p_max  = torch.cat(p_max_list).numpy()\n",
    "\n",
    "    num_classes = int(max(y_true.max(), y_hat.max())) + 1\n",
    "    accepted = (p_max >= thr)\n",
    "\n",
    "    gate = {\"selected_threshold\": float(thr), \"per_class\": {}, \"overall\": {}}\n",
    "\n",
    "    acc_on_accepted = float((y_hat[accepted] == y_true[accepted]).mean()) if accepted.any() else 0.0\n",
    "    coverage = float(accepted.mean())\n",
    "    gate[\"overall\"] = {\"acc_on_accepted\": acc_on_accepted, \"coverage\": coverage}\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        is_c = (y_true == c)\n",
    "        n_c  = int(is_c.sum())\n",
    "        if n_c == 0:\n",
    "            gate[\"per_class\"][str(c)] = {\"r\": None, \"a\": None, \"S_1mr\": None, \"S_full\": None}\n",
    "            continue\n",
    "\n",
    "        rc = float((~accepted[is_c]).mean())  # 真c被拒比例\n",
    "        mask_acc_c = accepted & is_c\n",
    "        ac = float((y_hat[mask_acc_c] == c).mean()) if mask_acc_c.any() else 0.0\n",
    "\n",
    "        gate[\"per_class\"][str(c)] = {\n",
    "            \"r\": rc,\n",
    "            \"a\": ac,\n",
    "            \"S_1mr\": 1.0 - rc,\n",
    "            \"S_full\": (1.0 - rc) * ac\n",
    "        }\n",
    "    return gate\n",
    "\n",
    "\n",
    "VAL_GATE_STATS = compute_val_gate_stats(\n",
    "    model, X_val, baseline_val, y_val, thr_star,\n",
    "    device=device, batch_size=CALIB_BATCHSIZE\n",
    ")\n",
    "VAL_SELECTED_THR = float(thr_star)\n",
    "\n",
    "with open(SAVE_JSON_PATH, \"w\") as f:\n",
    "    json.dump(VAL_GATE_STATS, f, indent=2)\n",
    "print(f\"[Saved] per-class gate stats -> {os.path.abspath(SAVE_JSON_PATH)}\")\n",
    "\n",
    "\n",
    "# ----------------- E) 用选定阈值输出逐类指标 & （可选）混淆矩阵 -----------------\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(X_val, baseline_val, y_val),\n",
    "    batch_size=256,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_true_list, y_hat_list, p_max_list = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, bb, yb in val_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        bb = bb.to(device, non_blocking=True).float().clamp_min(1e-8)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(xb, bb)\n",
    "        probs  = F.softmax(logits, dim=1)\n",
    "        p_max, y_hat = probs.max(dim=1)\n",
    "\n",
    "        y_true_list.append(yb.detach().cpu())\n",
    "        y_hat_list.append(y_hat.detach().cpu())\n",
    "        p_max_list.append(p_max.detach().cpu())\n",
    "\n",
    "y_true = torch.cat(y_true_list).numpy()\n",
    "y_hat  = torch.cat(y_hat_list).numpy()\n",
    "p_max  = torch.cat(p_max_list).numpy()\n",
    "\n",
    "accepted_mask = (p_max >= VAL_SELECTED_THR)\n",
    "num_classes = int(max(y_true.max(), y_hat.max())) + 1\n",
    "\n",
    "print(\"\\n==== Accuracy and Uncertainty Per Label (Validation @ selected threshold) ====\")\n",
    "overall_correct_conf = 0\n",
    "overall_total_conf   = 0\n",
    "overall_not_pred     = 0\n",
    "\n",
    "for c in range(num_classes):\n",
    "    mask_c  = (y_true == c)\n",
    "    total_c = int(mask_c.sum())\n",
    "    if total_c == 0:\n",
    "        continue\n",
    "\n",
    "    acc_max = float((y_hat[mask_c] == c).mean()) * 100.0\n",
    "\n",
    "    mask_acc = mask_c & accepted_mask\n",
    "    accept_c = int(mask_acc.sum())\n",
    "    if accept_c > 0:\n",
    "        acc_conf = float((y_hat[mask_acc] == c).mean()) * 100.0\n",
    "        correct_c = int((y_hat[mask_acc] == c).sum())\n",
    "        acc_conf_display = f\"{acc_conf:5.2f}%\"\n",
    "    else:\n",
    "        acc_conf_display = \"  NaN\"\n",
    "        correct_c = 0\n",
    "\n",
    "    not_pred_pct = float((~accepted_mask[mask_c]).mean()) * 100.0\n",
    "\n",
    "    overall_correct_conf += correct_c\n",
    "    overall_total_conf   += accept_c\n",
    "    overall_not_pred     += int((~accepted_mask[mask_c]).sum())\n",
    "\n",
    "    print(f\"Label {c:02d}: 总样本={total_c:4d}, \"\n",
    "          f\"argmax Acc={acc_max:5.2f}%, \"\n",
    "          f\"阈值 Acc={acc_conf_display:>6}, \"\n",
    "          f\"Not Predicted={not_pred_pct:5.2f}% \"\n",
    "          f\"(正确 {correct_c}/{accept_c})\")\n",
    "\n",
    "overall_acc_conf = (overall_correct_conf / overall_total_conf * 100.0) if overall_total_conf > 0 else 0.0\n",
    "overall_not_pred_pct = overall_not_pred / y_true.size * 100.0\n",
    "print(f\"\\nOverall Accuracy (on accepted): {overall_acc_conf:.2f}%\")\n",
    "print(f\"Overall Not Predicted Percentage: {overall_not_pred_pct:.2f}%\")\n",
    "print(f\"Selected threshold: {VAL_SELECTED_THR:.4f}\")\n",
    "\n",
    "# ——（可选）只在“被接收”的样本上画混淆矩阵 —— #\n",
    "PLOT_CM = True\n",
    "if PLOT_CM:\n",
    "    valid = accepted_mask\n",
    "    y_true_f = y_true[valid]\n",
    "    y_pred_f = y_hat[valid]\n",
    "    if y_true_f.size > 0:\n",
    "        labels_order = sorted(list(set(y_true_f.tolist()) | set(y_pred_f.tolist())))\n",
    "        cm = confusion_matrix(y_true_f, y_pred_f, labels=labels_order)\n",
    "\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=labels_order, yticklabels=labels_order)\n",
    "        plt.xlabel('Predicted Label'); plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix on Accepted Samples (Validation)')\n",
    "        plt.show()\n",
    "\n",
    "        cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                    xticklabels=labels_order, yticklabels=labels_order)\n",
    "        plt.xlabel('Predicted Label'); plt.ylabel('True Label')\n",
    "        plt.title('Normalized Confusion Matrix on Accepted Samples (Validation)')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"（所有验证样本都被拒识，跳过混淆矩阵绘制）\")\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================# =========================================================# =========================================================# =========================================================\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 0) 快速 sanity check（可选，但建议保留）\n",
    "# =========================================================\n",
    "assert X_test.dim() == 3, f\"X_test must be (N,C,L), got {X_test.shape}\"\n",
    "assert y_test.dim() == 1, f\"y_test must be (N,), got {y_test.shape}\"\n",
    "assert baseline_test.dim() == 1, f\"baseline_test must be (N,), got {baseline_test.shape}\"\n",
    "assert X_test.size(0) == y_test.size(0) == baseline_test.size(0), \"N mismatch among X_test/y_test/baseline_test\"\n",
    "\n",
    "# baseline 不能为 0（你前面的 hist 映射会 baseline/bin 做步长），这里做一个保险\n",
    "baseline_test = baseline_test.float().clamp_min(1e-8)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) 分批得到：y_true / argmax_pred / threshold_pred(-1拒识) / conf\n",
    "# =========================================================\n",
    "def batch_predict_test(model, X_test, baseline_test, y_test, device=\"cpu\", batch_size=32):\n",
    "    model.eval()\n",
    "    test_dataset = TensorDataset(X_test, baseline_test, y_test)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_true, all_pred_max, all_pred_conf, all_conf = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, bb, yb in test_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            bb = bb.to(device, non_blocking=True).float().clamp_min(1e-8)\n",
    "            yb = yb.to(device, non_blocking=True).long()\n",
    "\n",
    "            logits = model(xb, bb)                 # ✅ baseline-aware forward\n",
    "            pm = logits.argmax(dim=1)              # argmax pred\n",
    "\n",
    "            # ✅ 推荐：直接用你模型自带 predict（它内部用 model.threshold）\n",
    "            pc, conf = model.predict(xb, bb)       # threshold pred (-1 for reject)\n",
    "\n",
    "            all_true.append(yb.cpu())\n",
    "            all_pred_max.append(pm.cpu())\n",
    "            all_pred_conf.append(pc.cpu())\n",
    "            all_conf.append(conf.cpu())\n",
    "\n",
    "    all_true      = torch.cat(all_true)\n",
    "    all_pred_max  = torch.cat(all_pred_max)\n",
    "    all_pred_conf = torch.cat(all_pred_conf)\n",
    "    all_conf      = torch.cat(all_conf)\n",
    "    return all_true, all_pred_max, all_pred_conf, all_conf\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) 输出：每类 argmax acc / 阈值 acc(只在被接收样本上) / 拒识率\n",
    "# =========================================================\n",
    "def report_per_class_metrics(all_true, all_pred_max, all_pred_conf):\n",
    "    num_classes = int(all_true.max().item()) + 1\n",
    "\n",
    "    print(\"\\n=== 测试集上各标签准确度（baseline-aware, 分批计算） ===\")\n",
    "    overall_correct_conf = 0\n",
    "    overall_total_conf   = 0\n",
    "    overall_reject       = 0\n",
    "    overall_total        = all_true.numel()\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        mask_c  = (all_true == c)\n",
    "        total_c = int(mask_c.sum().item())\n",
    "        if total_c == 0:\n",
    "            continue\n",
    "\n",
    "        # argmax acc（不拒识）\n",
    "        correct_max_c = int((all_pred_max[mask_c] == c).sum().item())\n",
    "        acc_max = 100.0 * correct_max_c / total_c\n",
    "\n",
    "        # threshold acc（只在被接收样本上算）\n",
    "        accepted_c_mask = mask_c & (all_pred_conf != -1)\n",
    "        accept_c = int(accepted_c_mask.sum().item())\n",
    "        if accept_c > 0:\n",
    "            correct_conf_c = int((all_pred_conf[accepted_c_mask] == c).sum().item())\n",
    "            acc_conf = 100.0 * correct_conf_c / accept_c\n",
    "            acc_conf_display = f\"{acc_conf:5.2f}%\"\n",
    "        else:\n",
    "            correct_conf_c = 0\n",
    "            acc_conf_display = \"  NaN \"\n",
    "\n",
    "        # 拒识率\n",
    "        reject_c = int((mask_c & (all_pred_conf == -1)).sum().item())\n",
    "        reject_pct = 100.0 * reject_c / total_c\n",
    "\n",
    "        overall_correct_conf += correct_conf_c\n",
    "        overall_total_conf   += accept_c\n",
    "        overall_reject       += reject_c\n",
    "\n",
    "        print(f\"Label {c:02d}: 总样本={total_c:4d}, \"\n",
    "              f\"argmax Acc={acc_max:6.2f}%, \"\n",
    "              f\"阈值 Acc={acc_conf_display:>6}, \"\n",
    "              f\"Reject={reject_pct:6.2f}% \"\n",
    "              f\"(正确 {correct_conf_c}/{accept_c})\")\n",
    "\n",
    "    overall_acc_conf = 100.0 * overall_correct_conf / overall_total_conf if overall_total_conf > 0 else 0.0\n",
    "    overall_coverage = 100.0 * overall_total_conf / overall_total if overall_total > 0 else 0.0\n",
    "    overall_reject_pct = 100.0 * overall_reject / overall_total if overall_total > 0 else 0.0\n",
    "\n",
    "    print(\"\\n--- Overall (threshold-based) ---\")\n",
    "    print(f\"Accuracy on accepted: {overall_acc_conf:.2f}%\")\n",
    "    print(f\"Coverage (accepted):  {overall_coverage:.2f}%\")\n",
    "    print(f\"Reject rate:          {overall_reject_pct:.2f}%\")\n",
    "\n",
    "    return num_classes\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) 混淆矩阵（只在 accepted 样本上画）\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_on_accepted(\n",
    "    all_true, all_pred_conf,\n",
    "    title_prefix=\"Test\",\n",
    "    save_csv=False,\n",
    "    csv_prefix=\"cm_test\"\n",
    "):\n",
    "    accepted = (all_pred_conf != -1)\n",
    "    y_true_f = all_true[accepted].numpy()\n",
    "    y_pred_f = all_pred_conf[accepted].numpy()\n",
    "\n",
    "    if y_true_f.size == 0:\n",
    "        print(\"（所有测试样本都被拒识，跳过混淆矩阵绘制）\")\n",
    "        return\n",
    "\n",
    "    labels_order = sorted(list(set(y_true_f.tolist()) | set(y_pred_f.tolist())))\n",
    "    cm = confusion_matrix(y_true_f, y_pred_f, labels=labels_order)\n",
    "\n",
    "    # ================== 新增：打印“绝对值”混淆矩阵 ==================\n",
    "    cm_df = pd.DataFrame(cm, index=labels_order, columns=labels_order)\n",
    "    print(f\"\\n==== {title_prefix} Confusion Matrix on Accepted Samples (Absolute) ====\")\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None, \"display.width\", 200):\n",
    "        print(cm_df)\n",
    "\n",
    "    # ================== 绘图：绝对值 ==================\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=labels_order, yticklabels=labels_order)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"{title_prefix} Confusion Matrix on Accepted Samples (Absolute)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ================== 归一化（按行） ==================\n",
    "    cm_norm = cm.astype(float) / np.clip(cm.sum(axis=1, keepdims=True), 1, None)\n",
    "\n",
    "    # ================== 新增：打印“归一化”混淆矩阵 ==================\n",
    "    cm_norm_df = pd.DataFrame(cm_norm, index=labels_order, columns=labels_order)\n",
    "    print(f\"\\n==== {title_prefix} Confusion Matrix on Accepted Samples (Normalized, row-wise) ====\")\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None, \"display.width\", 200):\n",
    "        print(cm_norm_df.round(4))\n",
    "\n",
    "    # ================== 绘图：归一化 ==================\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=labels_order, yticklabels=labels_order)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"{title_prefix} Confusion Matrix on Accepted Samples (Normalized)\")\n",
    "    plt.show()\n",
    "\n",
    "    # ================== 可选：保存为 CSV ==================\n",
    "    #if save_csv:\n",
    "        #cm_df.to_csv(f\"{csv_prefix}_absolute.csv\", index=True)\n",
    "        #cm_norm_df.to_csv(f\"{csv_prefix}_normalized.csv\", index=True)\n",
    "        #print(f\"\\n[Saved] {csv_prefix}_absolute.csv\")\n",
    "        #print(f\"[Saved] {csv_prefix}_normalized.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4) 一键运行（假设 model.threshold 已经用验证集校准好）\n",
    "# =========================================================\n",
    "model.eval()\n",
    "\n",
    "all_true, all_pred_max, all_pred_conf, all_conf = batch_predict_test(\n",
    "    model, X_test, baseline_test, y_test,\n",
    "    device=device,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "num_classes = report_per_class_metrics(all_true, all_pred_max, all_pred_conf)\n",
    "\n",
    "PLOT_CM = True\n",
    "if PLOT_CM:\n",
    "    plot_confusion_matrix_on_accepted(all_true, all_pred_conf, title_prefix=\"Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
